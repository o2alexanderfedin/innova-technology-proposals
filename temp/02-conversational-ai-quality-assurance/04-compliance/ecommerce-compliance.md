# E-Commerce Consumer Protection Compliance for Chatbots

**Research Date**: January 2025
**Sprint**: 02 - Conversational AI Quality Assurance
**Task**: 04 - Certification Pathway & Testing Strategy
**Researcher**: Compliance Analyst Skill

## Executive Summary

E-commerce conversational AI operates under an evolving patchwork of consumer protection laws focused on disclosure, accuracy, and liability for chatbot-facilitated transactions. Multiple U.S. states enacted chatbot disclosure requirements in 2024 (Utah, Maine) mandating clear notification when consumers interact with AI rather than humans, with penalties up to $2,500 per violation plus disgorgement of revenue. The FTC's September 2024 "Operation AI Comply" enforcement sweep resulted in penalties including $193,000 against DoNotPay for deceptive AI claims, establishing that Section 5's prohibition on unfair and deceptive practices applies fully to chatbots with no "AI exemption." European enforcement demonstrates even higher stakes: under the Product Liability Directive (applicable December 2026), businesses remain fully liable for misleading or incorrect chatbot information, with British Columbia tribunal requiring airline to honor erroneous discount provided by chatbot. For Innova, e-commerce represents a massive addressable market—the global chatbot market reached $7.76 billion in 2024 and projects to $27.29 billion by 2030 (23.3% CAGR)—where SMT-based validation can prove chatbots provide accurate pricing, product information, and transactional capabilities while maintaining required disclosures, transforming compliance from legal risk into customer trust advantage.

## Key Compliance Requirements

- **Bot Disclosure Laws**: Utah, Maine, California, New Jersey require disclosure when consumers interact with AI
- **FTC Section 5**: Unfair or deceptive practices prohibition applies to chatbot communications and transactions
- **Pricing Accuracy**: Businesses liable for incorrect pricing provided by chatbots (British Columbia precedent)
- **Product Information Accuracy**: Misrepresentation of product features, availability, or specifications violates consumer protection laws
- **EU Product Liability Directive**: Full liability for chatbot errors applies December 2026
- **EU AI Act Transparency**: Limited-risk chatbots must disclose AI nature by February 2, 2025
- **Right to Human Escalation**: Many jurisdictions require option to escalate from chatbot to human agent
- **Penalties**: Utah $2,500/violation + disgorgement; FTC $193,000 (DoNotPay precedent); EU fines €7.5M or 1.5% global turnover

## State Bot Disclosure Laws

### Utah Artificial Intelligence Policy Act (2024)

**Effective Date**: May 2024 (first AI-focused consumer protection law in U.S.)

**Core Disclosure Requirement**:
Consumer-facing bots must disclose, **upon being asked**, that the consumer is interacting with "generative artificial intelligence and not a human."

**Proactive Disclosure for Regulated Occupations**:
For **regulated occupations** (those requiring license or state certification such as legal, medical, financial advisory), consumer does **not** need to request disclosure—**proactive disclosure of bot usage is required**.

**Disclosure Standards**:
- Must be **clear and conspicuous**
- Provided in plain language understandable to average consumer
- Cannot be buried in terms of service or privacy policy
- Must occur before or at the beginning of substantive interaction

**Enforcement**:
- **Utah Division of Consumer Protection**: Administrative fines up to **$2,500 per violation**
- **Utah Attorney General**: Declaratory and injunctive relief, disgorgement of money received in violation of AIPA
- Private right of action not explicitly created, but AG can act on consumer complaints

**Example Compliant Disclosure**:
> "You're chatting with an AI assistant. While I can help with product information and order tracking, I'm powered by artificial intelligence. You can request to speak with a human agent at any time by typing 'agent.'"

**E-commerce Implications**:
- Standard e-commerce customer service chatbots must respond to disclosure requests ("Are you a bot?", "Am I talking to a human?")
- Legal advice chatbots (helping with terms of service, contracts) require proactive disclosure
- Financial product chatbots (credit cards, buy-now-pay-later) may require proactive disclosure depending on state licensing

### Maine Chatbot Disclosure Act (2024)

**Effective Date**: June 2024

**Core Requirement**:
Businesses using AI chatbots to communicate with consumers must **notify those consumers** that they are not interacting with a live human.

**Disclosure Standards**:
- **Clear and conspicuous** notification
- Provided **before or at the beginning** of interaction
- Easily understandable to consumers
- No specific language prescribed, allowing flexibility

**Scope**:
- Applies to businesses operating in Maine or serving Maine consumers
- Covers chatbots used for customer service, sales, technical support, marketing
- Both B2C and B2B interactions where "consumer" broadly defined

**Enforcement**:
- Maine Attorney General enforcement authority
- Violations subject to Maine Unfair Trade Practices Act remedies
- No specific penalty amount stated, but UTPA allows civil penalties and injunctive relief

**Comparison to Utah**:
- Maine requires **proactive disclosure for all chatbots** (not just regulated occupations)
- Utah allows reactive disclosure (upon request) for most chatbots
- Maine does not specify "generative AI" language, applies to all chatbot technology

### California Bot Disclosure Law

**Statute**: California Business and Professions Code § 17940 (enacted 2018, effective 2019)

**Prohibition**:
Unlawful to use bot to communicate or interact with person in California online with intent to mislead about its artificial identity for purpose of:
- Incentivizing purchase or sale of goods or services in commercial transaction
- Influencing vote in election

**Disclosure Requirement**:
Person using bot must disclose that it is a bot (specific language: "clearly disclose that it is a bot")

**Exceptions**:
Disclosure not required if bot's artificial identity would be **obvious to reasonable person** from context

**Enforcement**:
- California Attorney General or local prosecutor
- No specific penalty amount in statute
- Subject to general unfair competition remedies

**E-commerce Application**:
- Shopping assistant chatbots must disclose bot nature
- Product recommendation chatbots require disclosure if incentivizing purchases
- Marketing/promotional chatbots trigger disclosure requirement
- Purely informational chatbots (store hours, shipping policies) may be exempt if bot nature obvious

### New Jersey Bot Prohibition

**Statute**: N.J.S.A. 56:8-196 (Prohibits Bots from Conducting Commercial Transactions)

**Prohibition**:
Prohibits using bots to **knowingly deceive** consumers in connection with online commercial transactions without disclosure.

**Focus**: Deception rather than mere bot use—honest bots with disclosure are permissible.

**Disclosure Requirement**:
Must disclose bot identity to avoid deception claim.

**Enforcement**:
- New Jersey Consumer Fraud Act remedies
- Civil penalties up to $10,000 for first violation, $20,000 for subsequent violations
- Attorney General enforcement and private right of action

**E-commerce Significance**:
New Jersey specifically targets commercial transactions, making e-commerce chatbots prime enforcement target if disclosure lacking.

## FTC Section 5 Enforcement: Operation AI Comply

### FTC Authority and Scope

**Section 5(a) of FTC Act** prohibits "unfair or deceptive acts or practices in or affecting commerce."

**FTC Position on AI (2024)**: "There is **no AI exemption** from the laws on the books." - FTC Chair Lina Khan

**Deceptive Practices Standard**:
1. **Representation, omission, or practice** likely to mislead consumers
2. **Reasonable consumer** standard (from consumer's perspective)
3. **Material** to consumer's decision-making

**Unfair Practices Standard**:
1. Causes or likely to cause **substantial injury** to consumers
2. Injury **not reasonably avoidable** by consumers
3. Injury **not outweighed** by countervailing benefits

### Operation AI Comply Cases (September 2024)

**DoNotPay - $193,000 Settlement**:

**Alleged Violations**:
- Advertised "robot lawyer" or "AI lawyer" chatbot claiming to give legal advice and draft legal documents
- Represented service as "ironclad" and would "replace the $200-billion-dollar legal industry with artificial intelligence"
- Made these claims without lawyer oversight or bar admission

**FTC Findings**:
- Deceptive claims about chatbot's legal capabilities
- Misrepresenting AI as substitute for licensed attorney
- No evidence supporting "ironclad" or industry-replacement claims

**Settlement Terms**:
- **$193,000 civil penalty**
- **Notice to customers** about limitations of services
- **Prohibition** on making unsubstantiated claims about AI capabilities
- Requirement to clearly disclose that DoNotPay is not a law firm and does not provide legal services

**E-commerce Lessons**:
- Cannot claim chatbot performs services requiring professional licensing (legal, medical, etc.)
- Performance claims ("ironclad," "guaranteed," "perfect") require substantiation
- Marketing language must accurately reflect chatbot limitations

**Rytr - AI-Generated Fake Review Violations**:

**Alleged Violations**:
- Advertised AI-enabled "writing assistant" with specific functionality to generate fake online customer reviews
- AI-generated reviews contained fabricated details designed to deceive potential consumers

**FTC Charge**:
"Unfair or deceptive acts or practices in or affecting commerce in violation of Section 5(a) of the Federal Trade Commission Act"

**Significance**:
- Using AI to generate deceptive content (fake reviews) violates FTC Act
- Chatbots generating fraudulent product information, testimonials, or endorsements subject to enforcement
- Tool providers liable for creating functionality designed for deceptive purposes

**E-commerce Implication**:
- Product description chatbots must not fabricate features or benefits
- Review/testimonial generation by AI must be disclosed
- "AI hallucinations" creating false product information may constitute deceptive practices

**Three Additional Cases**:
FTC announced enforcement against three companies using "hype around AI to lure consumers into bogus schemes," though specific details not fully disclosed as of January 2025.

### FTC's Five "Don'ts" for AI Chatbots

Following Operation AI Comply, FTC outlined five categories of prohibited practices:

**1. Don't Make Unsupported Claims About AI Capabilities**:
- Claims of accuracy, performance, or reliability require substantiation
- Comparative claims ("better than humans," "more accurate than experts") need proof
- Avoid superlatives ("perfect," "flawless," "never wrong") unless literally true

**2. Don't Use AI to Amplify Deceptive Practices**:
- AI-generated fake reviews, testimonials, or endorsements prohibited
- Synthetic voices or personas must be disclosed
- Bot-generated social proof ("1,000 satisfied customers") must be accurate

**3. Don't Ignore Discriminatory Impacts**:
- AI that discriminates based on protected characteristics violates FTC Act
- Disparate impact in pricing, product availability, or service quality actionable
- Regular testing for algorithmic bias required

**4. Don't Make Claims About Privacy/Security You Can't Keep**:
- If claiming chatbot protects user data, implement adequate safeguards
- Data minimization claims must be accurate (don't collect more than stated)
- Encryption, anonymization, or other security claims require implementation

**5. Don't Abdicate Responsibility by Blaming the Algorithm**:
- "The AI made the mistake" is not a defense
- Companies remain liable for chatbot errors
- Continuous monitoring and quality control required

## Product Information Accuracy and Liability

### British Columbia Civil Resolution Tribunal Precedent

**Case**: Air Canada v. Consumer (2024 decision gaining widespread attention)

**Facts**:
- Consumer interacted with Air Canada chatbot asking about bereavement fares
- Chatbot provided incorrect information about fare eligibility and retroactive application
- Consumer purchased full-price ticket relying on chatbot's representation
- Air Canada refused to honor chatbot's misinformation

**Tribunal Finding**:
- Air Canada **liable for chatbot's incorrect information**
- Consumer had no reason to doubt chatbot's accuracy
- Chatbot is Air Canada's agent; company responsible for agent's statements
- Air Canada **ordered to honor the discount** plus damages

**Tribunal Reasoning**:
"While a chatbot has an interactive component, it is still just a part of Air Canada's website. It should be obvious to Air Canada that it is responsible for all the information on its website. There is no reason why Mr. Moffatt should know that one section of Air Canada's website is accurate, and another is not."

**Global Impact**:
This decision, though from small-claims tribunal, has been cited worldwide as precedent for chatbot liability, influencing consumer protection enforcement and corporate risk assessments.

### EU Product Liability Directive (Revised 2024)

**Applicability Date**: December 2026

**Key Provision**:
Businesses remain **fully responsible for all communications with consumers**, including those conducted through AI chatbots.

**Liability Standard**:
Companies can be held **accountable and liable for any misleading or incorrect information** provided by a chatbot.

**Examples of Liability**:
- Chatbot states product has feature it lacks → Product liability and consumer protection violations
- Chatbot provides incorrect pricing → Business may be required to honor stated price
- Chatbot misrepresents delivery timeframes → Potential compensation for consumer harm
- Chatbot gives wrong product compatibility information → Liability for resulting damages

**Defense Limitations**:
"Companies **cannot use the fact that statements were uttered by a bot** as a defense against violations" - regulatory guidance

**Enforcement**:
- National consumer protection authorities in EU member states
- Private litigation by harmed consumers
- Potential class actions for systematic chatbot errors

### U.S. Consumer Protection Implications

**Magnuson-Moss Warranty Act**:
- Chatbots making warranty claims or representations create enforceable warranties
- "This product is guaranteed for 5 years" by chatbot = binding warranty
- Disclaimers must be clear and conspicuous (chatbot fine print may be insufficient)

**State Consumer Protection Statutes (UDAP laws)**:
- All 50 states have Unfair and Deceptive Acts and Practices statutes
- Chatbot misrepresentations about products violate UDAP laws
- Remedies include actual damages, statutory damages, attorney's fees, injunctive relief
- Some states allow treble damages for willful violations

**Common Law Fraud and Misrepresentation**:
- Chatbot's false statement of material fact can constitute fraud
- Consumer reliance on chatbot's representation element of claim
- Damages for economic harm resulting from misrepresentation

### Accuracy Requirements and Best Practices

**Pricing Accuracy**:
- Real-time synchronization between chatbot and pricing database
- Validation before presenting price to consumer
- Clear disclaimers if prices subject to change ("Prices subject to availability")
- Honor erroneous prices if consumer reasonably relied (Air Canada precedent)

**Product Availability**:
- Inventory integration to avoid advertising unavailable products
- Clear distinction between "in stock," "available for order," "backordered"
- Realistic delivery timeframe estimates based on actual fulfillment data
- Update customers proactively if availability changes after chatbot interaction

**Product Specifications and Features**:
- Chatbot training data must match current product catalog
- Regular updates when products change or new SKUs added
- Validation against authoritative product information management (PIM) system
- Hallucination detection to prevent AI fabricating non-existent features

**Returns, Refunds, and Policies**:
- Chatbot must accurately state current return policy
- Changes to policies require immediate chatbot retraining
- Cannot make exceptions to policy unless authorized
- Terms stated by chatbot may become contractually binding

## Human Escalation and Consumer Rights

### Right to Human Interaction

**Emerging Legal Principle**: Consumers should have option to interact with human rather than being forced to use chatbot.

**California Regulatory Trend**:
While not yet codified in bot disclosure law, consumer advocates push for "right to human" in customer service contexts, especially for:
- Complaints and dispute resolution
- Complex transactions or troubleshooting
- Vulnerable populations (elderly, disabled, limited English proficiency)
- High-value purchases or consequential decisions

**European Union Position**:
EU AI Act emphasizes human oversight and ability for humans to override AI decisions, implying consumers should have human escalation option.

**Best Practice Standard (2024)**:
- Clearly disclose how to reach human agent ("Type 'agent' to speak with a person")
- Reasonable wait times for human escalation (not hours-long delays)
- Don't create chatbot "traps" preventing access to humans
- Automatic escalation for certain issues (complaints, refund requests, accessibility needs)

### Accessibility Requirements

**ADA (Americans with Disabilities Act) Application**:
Chatbots on e-commerce websites constitute "public accommodation" under Title III of ADA (per Department of Justice position).

**WCAG (Web Content Accessibility Guidelines) Compliance**:
- Chatbot interface must be navigable by keyboard (for motor impairments)
- Screen reader compatible (for visual impairments)
- Clear language and simple interactions (for cognitive impairments)
- Color contrast and text sizing options

**Chatbot-Specific Accessibility Challenges**:
- Conversational UI may be difficult for screen readers
- Time-limited responses disadvantage users with cognitive processing differences
- Lack of visual cues compared to traditional web interfaces
- Complex natural language may confuse users with language disabilities

**Remediation Requirements**:
- Alternative communication methods (phone, email, live chat with human)
- Plain language option for chatbot
- Extended time for responses
- Visual and audio modalities

## Disclaimers and Limitations of Liability

### Effectiveness of Chatbot Disclaimers

**General Principle**: Disclaimers **do not eliminate liability** for deceptive or unfair practices, but may limit scope in certain contexts.

**Effective Disclaimers**:
- **Prominent placement**: Beginning of chatbot interaction, not buried in T&Cs
- **Clear language**: Plain English, not legalese
- **Specific content**: "This chatbot provides general information only. Product specifications, pricing, and availability should be confirmed before purchase."
- **Repeated when necessary**: Redisplay disclaimer at critical moments (before transaction completion)

**Ineffective Disclaimers**:
❌ "Use of chatbot subject to Terms of Service at www.example.com/terms"
❌ Fine print at bottom of chat window
❌ Legal jargon ("Company disclaims all warranties express or implied...")
❌ Contradicted by chatbot's confident assertions ("I guarantee this product will work for your needs" followed by disclaimer)

**Best Practice Disclaimer Example**:
> "I'm an AI assistant designed to help with product information and orders. While I strive for accuracy, I may occasionally make mistakes. Please verify important details like pricing, specifications, and delivery dates before completing your purchase. For complex questions or if you need assistance, I can connect you with a human specialist."

### Limitation of Liability Clauses

**Contract Law Constraints**:
- Terms of service with limitation of liability apply to chatbot interactions
- Must be presented to consumer before forming contract (clickwrap or browsewrap)
- Unconscionable limitations may be unenforceable
- Cannot disclaim liability for fraud, gross negligence, or intentional misconduct

**Consumer Protection Override**:
- State consumer protection statutes often prohibit waiver of consumer rights
- FTC Act violations cannot be contractually waived
- EU consumer protection laws make certain liability limitations void

**Recommended Approach**:
Focus on **accuracy and quality control** rather than relying on disclaimers to shield from liability. Disclaimers supplement but don't replace responsible chatbot design.

## Recommendations for Innova's E-Commerce Compliance Strategy

### Technical Validation Capabilities

**1. Disclosure Compliance Testing** (Q1 2025):
- Automated validation that chatbots provide required bot disclosure
- Multi-state compliance (Utah, Maine, California, New Jersey)
- Testing disclosure triggers ("Are you a bot?", "Can I speak to a human?")
- Verification of disclosure prominence and clarity
- Regulatory jurisdiction detection (chatbot adapts disclosure based on user location)

**2. Accuracy Validation Framework** (Q1-Q2 2025):
- **Pricing accuracy**: Verify chatbot-stated prices match product database
- **Inventory accuracy**: Confirm availability claims synchronized with inventory system
- **Product specification accuracy**: Validate chatbot descriptions against PIM/catalog
- **Policy accuracy**: Test that chatbot correctly states return, shipping, warranty policies
- **Hallucination detection**: Identify when chatbot fabricates non-existent information

**3. FTC Section 5 Compliance Testing** (Q2 2025):
- **Deceptive claims detection**: Flag unsubstantiated performance claims, superlatives, guarantees
- **Fake content identification**: Detect AI-generated reviews, testimonials, endorsements
- **Comparative claims validation**: Verify "better than" or "best" claims have evidentiary support
- **Material omission detection**: Identify missing disclosures or important caveats

**4. Human Escalation Validation** (Q2 2025):
- Verify escalation mechanisms function correctly
- Test escalation triggers (complaints, refund requests, confusion indicators)
- Monitor escalation wait times and accessibility
- Validate chatbot doesn't obstruct access to humans

### SMT-Based Formal Verification Advantages

**Proof of Accuracy**:
Unlike statistical testing, SMT solvers provide **mathematical proof** that chatbot cannot provide information contradicting source data (product catalog, pricing database, policy documents).

**Exhaustive Coverage**:
SMT verification explores **all possible chatbot responses** for given inputs, not just sampled test cases—critical for proving compliance with accuracy requirements.

**Explainable Compliance**:
SMT-based approach generates **verifiable evidence** for regulators and courts that chatbot cannot engage in prohibited behaviors (deceptive claims, fake information, discriminatory responses).

**Update Validation**:
When product catalog, pricing, or policies change, SMT re-verification proves chatbot updated correctly—avoiding Air Canada scenario where chatbot gave outdated information.

### Market Positioning for E-Commerce

**Target Segments**:

**1. High-Volume E-Commerce Retailers** (Primary Target):
- Massive chatbot interaction volumes = high violation exposure
- Brand reputation risk from chatbot errors
- Complex product catalogs requiring accuracy validation
- Multi-state operations requiring jurisdiction-specific compliance

**2. Marketplace Platforms** (High Priority):
- Liability for third-party seller chatbots on platform
- Regulatory scrutiny of platform facilitation of deceptive practices
- Need to enforce chatbot standards across sellers

**3. Consumer Electronics and High-Value Goods**:
- Technical specifications critical (compatibility, features)
- High consumer reliance on chatbot product information
- Significant financial harm from errors (wrong compatibility → expensive return)

**4. Regulated Products** (Supplements, Financial Services on E-Commerce):
- Additional disclosure requirements beyond general e-commerce
- FTC/FDA/CFPB scrutiny of chatbot claims
- Higher penalties for violations

### Value Proposition and ROI

**Avoided Liability**:
- FTC penalties: $193,000 (DoNotPay precedent for single violation)
- State UDAP violations: $10,000-$20,000 per violation (New Jersey), potentially thousands of violations from chatbot errors
- Consumer litigation: Class actions for systematic chatbot errors (damages + attorney's fees)
- Brand harm: Difficult to quantify but potentially millions in lost sales and reputation damage

**Example**: Air Canada chatbot error resulted in tribunal case, negative global media coverage, operational disruption—estimated impact $500K+ for single consumer interaction.

**Reduced Customer Service Costs**:
- Accurate chatbots reduce human escalations (each escalation costs $5-$15)
- Fewer returns from incorrect product information (return costs 20-30% of sale price)
- Decreased dispute resolution and complaint handling

**Increased Conversion**:
- Consumer trust in accurate chatbots → higher purchase completion rates
- Verified accuracy claims differentiate in competitive markets
- "Innova Verified Chatbot" certification mark signals reliability

**Pricing Strategy**:
- **SMB E-Commerce** (< $10M revenue): $25,000-$50,000/year
- **Mid-Market** ($10M-$100M revenue): $50,000-$150,000/year
- **Enterprise Retailer** ($100M-$1B revenue): $150,000-$400,000/year
- **Major E-Commerce Platform** ($1B+ revenue): $400,000-$1M/year

**ROI Calculation Example - Mid-Market Retailer**:
- Innova Platform: $100,000/year
- Avoided FTC/state penalties: $200,000 (expected value = 10% probability × $2M exposure)
- Reduced escalations: $75,000 (5,000 escalations avoided × $15)
- Prevented returns: $50,000 (500 returns × $100 average)
- Increased conversion: $150,000 (0.5% conversion lift × $30M revenue)
- **Total value**: $475,000 vs. $100,000 cost = **4.75x ROI**

### Go-to-Market Strategy

**Phase 1: Compliance Pain Points** (Q1-Q2 2025):
- Target e-commerce companies that have experienced chatbot errors or near-misses
- Partner with e-commerce platforms (Shopify, BigCommerce, WooCommerce) for app integration
- Create "State Bot Disclosure Compliance" quick-win product for Utah/Maine/California requirements

**Phase 2: Quality and Trust** (Q2-Q3 2025):
- Position as quality assurance tool, not just compliance
- "Innova Verified Chatbot" badge for websites demonstrating accuracy validation
- Case studies showing conversion and customer satisfaction improvements

**Phase 3: Platform Integration** (Q3-Q4 2025):
- Integrate with major chatbot platforms (Intercom, Drift, Zendesk, Salesforce Einstein)
- Offer continuous validation SaaS for real-time monitoring
- Expand to pre-deployment validation for chatbot development teams

## References

State of Utah. (2024). Artificial Intelligence Policy Act (S.B. 149). Effective May 1, 2024. https://le.utah.gov/

State of Maine. (2024). An Act Relating to the Disclosure of Artificial Intelligence in Communication with Consumers (Chatbot Disclosure Act). Effective June 2024. https://legislature.maine.gov/

State of California. (2018). California Business and Professions Code § 17940 (Bot Disclosure Law). Effective July 1, 2019. https://leginfo.legislature.ca.gov/

State of New Jersey. N.J.S.A. 56:8-196 - Prohibits Bots from Conducting Commercial Transactions. https://www.njleg.state.nj.us/

Federal Trade Commission. (2024). FTC Announces Crackdown on Deceptive AI Claims and Schemes (Operation AI Comply). September 25, 2024. https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes

Federal Trade Commission. (2024). DoNotPay Settlement - $193,000 penalty for deceptive AI lawyer claims. https://www.ftc.gov/

Federal Trade Commission Act, 15 U.S.C. § 45 (Section 5 - Unfair or Deceptive Acts or Practices).

European Union. (2024). Product Liability Directive (Revised). Applicable December 2026. https://ec.europa.eu/

British Columbia Civil Resolution Tribunal. (2024). Air Canada liability decision for chatbot misinformation. https://civilresolutionbc.ca/

Fenwick & West LLP. (2024). FTC Outlines Five Don'ts for AI Chatbots. https://www.fenwick.com/insights/publications/ftc-outlines-five-donts-for-ai-chatbots

Grand View Research. (2025). Chatbot Market Size, Share & Growth | Industry Report, 2030. https://www.grandviewresearch.com/industry-analysis/chatbot-market

Cooley LLP. (2024). AI Chatbots at the Crossroads: Navigating New Laws and Compliance Risks. https://www.cooley.com/news/insight/2025/2025-10-21-ai-chatbots-at-the-crossroads-navigating-new-laws-and-compliance-risks

Inside Privacy. (2024). Digital Fairness Act Series: Topic 2 – Transparency and Disclosure Obligations for AI Chatbots in Consumer Interactions. https://www.insideprivacy.com/artificial-intelligence/
